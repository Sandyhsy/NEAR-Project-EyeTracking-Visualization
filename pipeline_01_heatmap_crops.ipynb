{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d29f01d",
      "metadata": {},
      "source": [
        "# Gaze Heatmap & Crops Pipeline (Google Colab)\n",
        "\n",
        "This notebook processes **eye-tracking gaze data** from the NEAR Experiment Design dataset. For each user folder it:\n",
        "\n",
        "1. **Loads gaze data** (from Pupil exports CSV or pldata).\n",
        "2. **Splits the recording into time windows** (e.g. 3 s).\n",
        "3. **For each window:** grabs a video frame, builds a **heatmap** (2D histogram + Gaussian blur + jet colormap overlay), saves full-frame heatmap and source images, computes a **region of interest** from the heatmap, and saves **cropped** versions of both.\n",
        "4. **Builds an MP4** from the heatmap frames for easy playback.\n",
        "\n",
        "**Outputs per user** (under `BASE_OUTPUT_PATH/<user_name>/frames/`):\n",
        "\n",
        "- `src_000-003s.png`, `src_003-006s.png`, ... ‚Äî source video frame at mid-window.\n",
        "- `heat_000-003s.png`, `heat_003-006s.png`, ... ‚Äî heatmap overlay (same style as Data_Analysis original).\n",
        "- `src_*_crop.png`, `heat_*_crop.png` ‚Äî crops around the gaze-dense region.\n",
        "- `<user_name>_heatmap.mp4` ‚Äî video of heatmap frames in time order.\n",
        "\n",
        "Heatmap method matches the original Data_Analysis pipeline (2D histogram, Gaussian smoothing, jet colormap, matplotlib figure at 200 dpi)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf083218",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive\n",
        "\n",
        "Mount Drive so we can read the source dataset and write outputs. Run this cell first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ef06a61d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9625b937",
      "metadata": {},
      "source": [
        "## 2. Imports\n",
        "\n",
        "Libraries for gaze loading (including Pupil pldata via msgpack), video (OpenCV), heatmap (matplotlib, scipy), and MP4 writing (imageio, PIL).  \n",
        "If you get an import error, run: `%pip install msgpack scipy pillow imageio imageio-ffmpeg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "af0c1e14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries (heatmap from Data_Analysis_old_version)\n",
        "# If needed: %pip install msgpack scipy pillow imageio imageio-ffmpeg\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import msgpack\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ef6abf",
      "metadata": {},
      "source": [
        "## 3. Paths and user list\n",
        "\n",
        "- **BASE_SOURCE_PATH:** folder containing one subfolder per user (e.g. `Ayu_1`, `AT_1`), each with `world.mp4` and `exports/` (or pldata).\n",
        "- **BASE_OUTPUT_PATH:** where to write per-user `frames/` and heatmap MP4s.  \n",
        "We list all non-hidden subfolders of the source path as user folders (excluding `1_Data_Analysis`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5908a6ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 26 user folders:\n",
            "  - AT_1\n",
            "  - AT_2\n",
            "  - AT_3_1\n",
            "  - AT_3_2\n",
            "  - Ayu_1\n",
            "  - Ayu_2\n",
            "  - Ayu_3\n",
            "  - JC_1\n",
            "  - JC_2\n",
            "  - JC_3_1\n",
            "  ... and 16 more\n"
          ]
        }
      ],
      "source": [
        "# Where to read data (one subfolder per user: Ayu_1, AT_1, ...) and where to write results\n",
        "BASE_SOURCE_PATH = \"/content/drive/MyDrive/NEAR_Experiment_Design/PilotData_V1_10232025\"\n",
        "BASE_OUTPUT_PATH = \"/content/drive/MyDrive/NEAR_Experiment_Design_Output\"\n",
        "os.makedirs(BASE_OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Discover all user folders (each must contain world.mp4 and exports/ or pldata)\n",
        "user_folders = sorted([f for f in os.listdir(BASE_SOURCE_PATH) \n",
        "                       if os.path.isdir(os.path.join(BASE_SOURCE_PATH, f)) \n",
        "                       and not f.startswith('.')\n",
        "                       and f not in ['1_Data_Analysis']])  # Skip non-user folders\n",
        "print(f\"Found {len(user_folders)} user folders:\")\n",
        "for folder in user_folders[:10]:  # Show first 10\n",
        "    print(f\"  - {folder}\")\n",
        "if len(user_folders) > 10:\n",
        "    print(f\"  ... and {len(user_folders) - 10} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b0e3b4",
      "metadata": {},
      "source": [
        "## 4. Helper functions\n",
        "\n",
        "- **Gaze:** `load_gaze_dataframe(task_dir)` ‚Äî loads from `exports/**/gaze_positions.csv` or, if missing, from Pupil `.pldata`; returns DataFrame with `timestamp`, `norm_pos_x`, `norm_pos_y`, `confidence`.\n",
        "- **Video:** `open_world_video(task_dir)`, `grab_frame_at_time(cap, fps, t_sec)` ‚Äî open `world.mp4` and seek to a time.\n",
        "- **Heatmap:** `compute_heat(df_window, h, w)` ‚Äî 2D histogram of gaze (Y flipped) + Gaussian blur; used for crop bbox.  \n",
        "  `plot_and_save_heatmap(bg_rgb, df_window, path)` ‚Äî same heatmap drawn with matplotlib (jet, alpha 0.5), saved as PNG (200 dpi).\n",
        "- **Crop:** `bbox_from_heatmap_only(heat, pad, thresh)` ‚Äî bounding box from heat above threshold.\n",
        "- **MP4:** `sort_by_window(files)` (by start time in filename), `to_even_size`, `make_mp4_from_folder(folder, pattern, out_mp4, fps)` ‚Äî build MP4 from heatmap PNGs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b674334",
      "metadata": {},
      "source": [
        "## 5. Main processing function\n",
        "\n",
        "`process_user_folder(user_name, source_base_path, output_base_path, ...)` does everything for one user:\n",
        "\n",
        "1. Load gaze and open video; align gaze time to relative seconds (`t_rel`).\n",
        "2. For each time window: grab frame at window mid-time; save source PNG; build and save heatmap PNG; compute heat array and bbox; save source and heatmap crops (heatmap crop uses bbox scaled to figure size 2000√ó1200).\n",
        "3. Build `<user_name>_heatmap.mp4` from all `heat_*-*s.png` frames.\n",
        "\n",
        "Parameters: `interval_sec` (window length in seconds), `pad` (pixels around bbox for crop), `sample_windows` (cap number of windows if set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "80b40885",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap pipeline from Data_Analysis_old_version (Ayu_1_heatmap.mp4 style)\n",
        "def load_pldata_file(directory, topic):\n",
        "    ts_file = os.path.join(directory, f\"{topic}_timestamps.npy\")\n",
        "    mp_file = os.path.join(directory, f\"{topic}.pldata\")\n",
        "    data_list = []\n",
        "    if not (os.path.exists(ts_file) and os.path.exists(mp_file)):\n",
        "        return [], np.array([])\n",
        "    timestamps = np.load(ts_file)\n",
        "    with open(mp_file, \"rb\") as fh:\n",
        "        unpacker = msgpack.Unpacker(fh, raw=False, use_list=False)\n",
        "        for tpc, payload in unpacker:\n",
        "            datum = msgpack.unpackb(payload, raw=False, use_list=False)\n",
        "            data_list.append(datum)\n",
        "    return data_list, timestamps\n",
        "\n",
        "def pldata_gaze_to_dataframe(directory):\n",
        "    def _normalize_to_unit(series):\n",
        "        v = series.astype(float)\n",
        "        vmin, vmax = float(v.min()), float(v.max())\n",
        "        rng = vmax - vmin\n",
        "        if (vmin < 0) or (vmax > 1):\n",
        "            if rng <= 1.2:\n",
        "                v = (v - vmin) / max(rng, 1e-9)\n",
        "            elif rng <= 2.2 and (vmin >= -1.1) and (vmax <= 1.1):\n",
        "                v = (v + 1.0) / 2.0\n",
        "            else:\n",
        "                v = v.clip(0, 1)\n",
        "        return v\n",
        "    data_list, ts = load_pldata_file(directory, \"gaze\")\n",
        "    if len(ts) == 0:\n",
        "        return pd.DataFrame()\n",
        "    rows = []\n",
        "    for d, tt in zip(data_list, ts):\n",
        "        row = {\"timestamp\": float(d.get(\"timestamp\", tt))}\n",
        "        if \"norm_pos\" in d:\n",
        "            nx, ny = d[\"norm_pos\"][0], d[\"norm_pos\"][1]\n",
        "        else:\n",
        "            nx, ny = d.get(\"norm_pos_x\", np.nan), d.get(\"norm_pos_y\", np.nan)\n",
        "        row[\"norm_pos_x\"] = float(nx) if nx is not None else np.nan\n",
        "        row[\"norm_pos_y\"] = float(ny) if ny is not None else np.nan\n",
        "        row[\"confidence\"] = float(d.get(\"confidence\", np.nan))\n",
        "        rows.append(row)\n",
        "    df = pd.DataFrame(rows).dropna(subset=[\"norm_pos_x\", \"norm_pos_y\"])\n",
        "    if (df[\"norm_pos_x\"].min() < 0) or (df[\"norm_pos_x\"].max() > 1) or (df[\"norm_pos_y\"].min() < 0) or (df[\"norm_pos_y\"].max() > 1):\n",
        "        df[\"norm_pos_x\"] = _normalize_to_unit(df[\"norm_pos_x\"])\n",
        "        df[\"norm_pos_y\"] = _normalize_to_unit(df[\"norm_pos_y\"])\n",
        "    return df\n",
        "\n",
        "def exports_csv_to_dataframe(exports_dir):\n",
        "    candidates = glob.glob(os.path.join(exports_dir, \"**\", \"gaze_positions.csv\"), recursive=True)\n",
        "    if not candidates:\n",
        "        return pd.DataFrame()\n",
        "    path = candidates[0]\n",
        "    df = pd.read_csv(path)\n",
        "    ts_col = next((c for c in [\"gaze_timestamp\", \"timestamp\", \"world_timestamp\", \"time\", \"system_time\"] if c in df.columns), None)\n",
        "    if ts_col is None:\n",
        "        return pd.DataFrame()\n",
        "    if {\"norm_pos_x\", \"norm_pos_y\"}.issubset(df.columns):\n",
        "        out = pd.DataFrame()\n",
        "        out[\"timestamp\"] = df[ts_col].astype(float)\n",
        "        out[\"norm_pos_x\"] = df[\"norm_pos_x\"].astype(float)\n",
        "        out[\"norm_pos_y\"] = df[\"norm_pos_y\"].astype(float)\n",
        "        out[\"confidence\"] = df[\"confidence\"].astype(float) if \"confidence\" in df.columns else np.nan\n",
        "        return out.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    if {\"gaze_point_2d_x\", \"gaze_point_2d_y\"}.issubset(df.columns):\n",
        "        out = pd.DataFrame()\n",
        "        out[\"timestamp\"] = df[ts_col].astype(float)\n",
        "        out[\"norm_pos_x\"] = df[\"gaze_point_2d_x\"].astype(float)\n",
        "        out[\"norm_pos_y\"] = df[\"gaze_point_2d_y\"].astype(float)\n",
        "        out[\"confidence\"] = df[\"confidence\"].astype(float) if \"confidence\" in df.columns else np.nan\n",
        "        return out.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def load_gaze_dataframe(task_dir):\n",
        "    exports_dir = os.path.join(task_dir, \"exports\")\n",
        "    df_csv = exports_csv_to_dataframe(exports_dir)\n",
        "    if not df_csv.empty:\n",
        "        return df_csv\n",
        "    df_pl = pldata_gaze_to_dataframe(task_dir)\n",
        "    if not df_pl.empty:\n",
        "        return df_pl\n",
        "    raise FileNotFoundError(\"Could not load gaze data from exports CSV or pldata.\")\n",
        "\n",
        "def open_world_video(task_dir):\n",
        "    mp4_path = os.path.join(task_dir, \"world.mp4\")\n",
        "    if not os.path.exists(mp4_path):\n",
        "        cand = glob.glob(os.path.join(task_dir, \"**\", \"world.mp4\"), recursive=True)\n",
        "        if cand:\n",
        "            mp4_path = cand[0]\n",
        "    cap = cv2.VideoCapture(mp4_path)\n",
        "    if not cap.isOpened():\n",
        "        raise FileNotFoundError(f\"Cannot open video at: {mp4_path}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    duration = frame_count / fps if fps > 0 else 0.0\n",
        "    return cap, fps, frame_count, duration, width, height\n",
        "\n",
        "def grab_frame_at_time(cap, fps, t_sec):\n",
        "    frame_idx = int(round(t_sec * fps))\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "    ok, frame = cap.read()\n",
        "    return frame if ok else None\n",
        "\n",
        "def compute_heat(df_window, h, w, blur_ratio=0.05):\n",
        "    gx = df_window[\"norm_pos_x\"].to_numpy()\n",
        "    gy = 1.0 - df_window[\"norm_pos_y\"].to_numpy()\n",
        "    hist, _, _ = np.histogram2d(gy, gx, bins=[h, w], range=[[0, 1], [0, 1]])\n",
        "    fh = max(1, (int(blur_ratio * h) // 2) * 2 + 1)\n",
        "    fw = max(1, (int(blur_ratio * w) // 2) * 2 + 1)\n",
        "    heat = gaussian_filter(hist, sigma=(fh, fw), order=0)\n",
        "    return heat\n",
        "\n",
        "def plot_and_save_heatmap(bg_image_rgb, df_window, out_path_png, blur_ratio=0.05):\n",
        "    os.makedirs(os.path.dirname(out_path_png), exist_ok=True)\n",
        "    h, w = bg_image_rgb.shape[:2]\n",
        "    gx = df_window[\"norm_pos_x\"].to_numpy()\n",
        "    gy = 1.0 - df_window[\"norm_pos_y\"].to_numpy()\n",
        "    hist, _, _ = np.histogram2d(gy, gx, bins=[h, w], range=[[0, 1], [0, 1]])\n",
        "    fh = max(1, (int(blur_ratio * h) // 2) * 2 + 1)\n",
        "    fw = max(1, (int(blur_ratio * w) // 2) * 2 + 1)\n",
        "    heat = gaussian_filter(hist, sigma=(fh, fw), order=0)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(bg_image_rgb)\n",
        "    plt.imshow(heat, cmap=\"jet\", alpha=0.5)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig(out_path_png, dpi=200, bbox_inches=None, pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "def bbox_from_heatmap_only(hmap, pad=0, thresh=0.5):\n",
        "    if hmap.size == 0 or hmap.max() <= 0:\n",
        "        return None\n",
        "    hmap_n = hmap / hmap.max()\n",
        "    mask = hmap_n > thresh\n",
        "    ys, xs = np.where(mask)\n",
        "    if len(xs) == 0:\n",
        "        return None\n",
        "    x0, x1 = xs.min(), xs.max()\n",
        "    y0, y1 = ys.min(), ys.max()\n",
        "    x0, y0 = max(0, x0 - pad), max(0, y0 - pad)\n",
        "    x1, y1 = min(hmap.shape[1], x1 + pad), min(hmap.shape[0], y1 + pad)\n",
        "    return x0, y0, x1, y1\n",
        "\n",
        "def sort_by_window(files):\n",
        "    def key_fn(p):\n",
        "        m = re.search(r\"_(\\d+)-\\d+s\", os.path.basename(p))\n",
        "        return int(m.group(1)) if m else 10**9\n",
        "    return sorted(files, key=key_fn)\n",
        "\n",
        "def to_even_size(size):\n",
        "    w, h = size\n",
        "    w, h = w - (w % 2), h - (h % 2)\n",
        "    return (max(2, w), max(2, h))\n",
        "\n",
        "def make_mp4_from_folder(folder, pattern, out_mp4_path, fps=2):\n",
        "    files = sort_by_window(glob.glob(os.path.join(folder, pattern)))\n",
        "    if not files:\n",
        "        return\n",
        "    sizes = [Image.open(p).size for p in files]\n",
        "    common_size = Counter(sizes).most_common(1)[0][0]\n",
        "    target_size = to_even_size(common_size)\n",
        "    with imageio.get_writer(out_mp4_path, fps=fps, codec=\"libx264\", quality=8, macro_block_size=None) as writer:\n",
        "        for p in files:\n",
        "            im = Image.open(p).convert(\"RGB\")\n",
        "            if im.size != target_size:\n",
        "                im = im.resize(target_size, Image.LANCZOS)\n",
        "            writer.append_data(np.array(im))\n",
        "    print(f\"[video] Saved: {out_mp4_path} ({len(files)} frames)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "bd9799de",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_user_folder(user_name, source_base_path, output_base_path,\n",
        "                        interval_sec=3.0, pad=20, alpha=0.5, sample_windows=None):\n",
        "    \"\"\"Process one user: load gaze + video, build heatmaps per window, save crops and MP4.\"\"\"\n",
        "    user_source_path = os.path.join(source_base_path, user_name)\n",
        "    frames_dir = os.path.join(output_base_path, user_name, \"frames\")\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.isdir(user_source_path):\n",
        "        print(f\"‚ö†Ô∏è  {user_name}: folder not found\")\n",
        "        return False\n",
        "\n",
        "    print(f\"üìä Processing {user_name}...\")\n",
        "    try:\n",
        "        gaze_df = load_gaze_dataframe(user_source_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {user_name}: Failed to load gaze - {e}\")\n",
        "        return False\n",
        "    try:\n",
        "        cap, fps, frame_count, duration, W, H = open_world_video(user_source_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {user_name}: Failed to open video - {e}\")\n",
        "        return False\n",
        "\n",
        "    # Align gaze time to 0 and compute number of windows\n",
        "    t_min = float(gaze_df[\"timestamp\"].min())\n",
        "    gaze_df = gaze_df.assign(t_rel=gaze_df[\"timestamp\"] - t_min)\n",
        "    max_duration = min(duration, float(gaze_df[\"t_rel\"].max()))\n",
        "    num_windows = int(max_duration // interval_sec) + 1\n",
        "    if sample_windows is not None:\n",
        "        num_windows = min(num_windows, sample_windows)\n",
        "\n",
        "    processed = 0\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "    for k in range(num_windows):\n",
        "        start_t = k * interval_sec\n",
        "        end_t = min((k + 1) * interval_sec, max_duration)\n",
        "        if end_t <= start_t + 1e-6:\n",
        "            continue\n",
        "        win_mask = (gaze_df[\"t_rel\"] >= start_t) & (gaze_df[\"t_rel\"] < end_t)\n",
        "        df_win = gaze_df.loc[win_mask]\n",
        "        if df_win.empty:\n",
        "            continue\n",
        "\n",
        "        mid_t = 0.5 * (start_t + end_t)\n",
        "        frame_bgr = grab_frame_at_time(cap, fps, mid_t)\n",
        "        if frame_bgr is None:\n",
        "            continue\n",
        "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        win_tag = f\"{int(start_t):03d}-{int(end_t):03d}s\"\n",
        "        heat_path = os.path.join(frames_dir, f\"heat_{win_tag}.png\")\n",
        "        src_path = os.path.join(frames_dir, f\"src_{win_tag}.png\")\n",
        "\n",
        "        cv2.imwrite(src_path, frame_bgr)\n",
        "        plot_and_save_heatmap(frame_rgb, df_win, heat_path)\n",
        "\n",
        "        heat = compute_heat(df_win, H, W)\n",
        "        bbox = bbox_from_heatmap_only(heat, pad=pad)\n",
        "        if bbox is not None:\n",
        "            x0, y0, x1, y1 = bbox\n",
        "            crop_src = frame_bgr[y0:y1, x0:x1]\n",
        "            cv2.imwrite(os.path.join(frames_dir, f\"src_{win_tag}_crop.png\"), crop_src)\n",
        "            saved_heat = cv2.imread(heat_path)\n",
        "            if saved_heat is not None:\n",
        "                # Heatmap PNG is 2000x1200 (matplotlib fig 10x6 @ 200 dpi); scale bbox to crop it\n",
        "                H_fig, W_fig = 1200, 2000\n",
        "                sx, sy = W_fig / W, H_fig / H\n",
        "                x0f, x1f = int(x0 * sx), int(x1 * sx)\n",
        "                y0f, y1f = int(y0 * sy), int(y1 * sy)\n",
        "                crop_heat = saved_heat[y0f:y1f, x0f:x1f]\n",
        "                cv2.imwrite(os.path.join(frames_dir, f\"heat_{win_tag}_crop.png\"), crop_heat)\n",
        "            processed += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    heat_mp4_path = os.path.join(frames_dir, f\"{user_name}_heatmap.mp4\")\n",
        "    make_mp4_from_folder(frames_dir, \"heat_*-*s.png\", heat_mp4_path, fps=2)\n",
        "\n",
        "    print(f\"‚úÖ {user_name}: Processed {processed} intervals, heatmap MP4: {heat_mp4_path}\")\n",
        "    return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d8eea8",
      "metadata": {},
      "source": [
        "## 6. Run pipeline\n",
        "\n",
        "Set **SINGLE_USER** to a folder name (e.g. `\"Ayu_1\"`) to process only that user, or set to **`None`** to process **all users** in `user_folders`.  \n",
        "Outputs go under `BASE_OUTPUT_PATH/<user_name>/frames/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5f17c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 26 user(s): ['AT_1', 'AT_2', 'AT_3_1', 'AT_3_2', 'Ayu_1']...\n",
            "\n",
            "üìä Processing AT_1...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_1/frames/AT_1_heatmap.mp4 (24 frames)\n",
            "‚úÖ AT_1: Processed 24 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_1/frames/AT_1_heatmap.mp4\n",
            "üìä Processing AT_2...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_2/frames/AT_2_heatmap.mp4 (10 frames)\n",
            "‚úÖ AT_2: Processed 10 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_2/frames/AT_2_heatmap.mp4\n",
            "üìä Processing AT_3_1...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_3_1/frames/AT_3_1_heatmap.mp4 (7 frames)\n",
            "‚úÖ AT_3_1: Processed 7 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_3_1/frames/AT_3_1_heatmap.mp4\n",
            "üìä Processing AT_3_2...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_3_2/frames/AT_3_2_heatmap.mp4 (15 frames)\n",
            "‚úÖ AT_3_2: Processed 15 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/AT_3_2/frames/AT_3_2_heatmap.mp4\n",
            "üìä Processing Ayu_1...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_1/frames/Ayu_1_heatmap.mp4 (20 frames)\n",
            "‚úÖ Ayu_1: Processed 20 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_1/frames/Ayu_1_heatmap.mp4\n",
            "üìä Processing Ayu_2...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_2/frames/Ayu_2_heatmap.mp4 (14 frames)\n",
            "‚úÖ Ayu_2: Processed 14 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_2/frames/Ayu_2_heatmap.mp4\n",
            "üìä Processing Ayu_3...\n",
            "[video] Saved: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_3/frames/Ayu_3_heatmap.mp4 (26 frames)\n",
            "‚úÖ Ayu_3: Processed 26 intervals, heatmap MP4: /content/drive/MyDrive/NEAR_Experiment_Design_Output/Ayu_3/frames/Ayu_3_heatmap.mp4\n",
            "üìä Processing JC_1...\n"
          ]
        }
      ],
      "source": [
        "# --- Configuration ---\n",
        "INTERVAL_SEC = 3.0      # Time window length in seconds (e.g. 3 = one heatmap every 3 s)\n",
        "PAD = 20               # Extra pixels around heatmap ROI for crop\n",
        "SAMPLE_WINDOWS = None  # None = process full recording; set to int to limit number of windows per user\n",
        "\n",
        "# Process one user (set name) or all users (set to None)\n",
        "SINGLE_USER = None     # e.g. None for all users, or \"Ayu_1\" to run only that folder\n",
        "\n",
        "# --- Run ---\n",
        "users_to_run = [SINGLE_USER] if SINGLE_USER else user_folders\n",
        "print(f\"Processing {len(users_to_run)} user(s): {users_to_run[:5]}{'...' if len(users_to_run) > 5 else ''}\\n\")\n",
        "\n",
        "successful = 0\n",
        "failed = 0\n",
        "for user in users_to_run:\n",
        "    try:\n",
        "        result = process_user_folder(user, BASE_SOURCE_PATH, BASE_OUTPUT_PATH,\n",
        "                                     interval_sec=INTERVAL_SEC, pad=PAD, alpha=0.5,\n",
        "                                     sample_windows=SAMPLE_WINDOWS)\n",
        "        if result:\n",
        "            successful += 1\n",
        "        else:\n",
        "            failed += 1\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {user}: {e}\")\n",
        "        failed += 1\n",
        "\n",
        "print(f\"\\n‚úÖ Done: {successful} ok, {failed} failed. Outputs under: {BASE_OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159dbe5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To process only one user (e.g. for testing), set SINGLE_USER in the cell above:\n",
        "#   SINGLE_USER = \"Ayu_1\"\n",
        "# Then re-run the \"Run pipeline\" cell. To process everyone again, set:\n",
        "#   SINGLE_USER = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c8eb31",
      "metadata": {},
      "source": [
        "## 7. Check outputs\n",
        "\n",
        "Summarizes how many frames and crops were written per user. Run after the pipeline has finished."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c72dce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Output files for Ayu_1:\n",
            "  Source full frames: 20\n",
            "  Source crops:       20\n",
            "  Heat full frames:   20\n",
            "  Heat crops:         20\n",
            "  Total files:        81\n"
          ]
        }
      ],
      "source": [
        "def check_output_files(user_name):\n",
        "    \"\"\"Print a short summary of generated files for one user.\"\"\"\n",
        "    frames_dir = os.path.join(BASE_OUTPUT_PATH, user_name, \"frames\")\n",
        "    if not os.path.exists(frames_dir):\n",
        "        print(f\"  {user_name}: no output\")\n",
        "        return\n",
        "    files = sorted(os.listdir(frames_dir))\n",
        "    src_full = [f for f in files if f.startswith(\"src_\") and \"_crop\" not in f]\n",
        "    heat_full = [f for f in files if f.startswith(\"heat_\") and \"_crop\" not in f and not f.endswith(\".mp4\")]\n",
        "    heat_crop = [f for f in files if \"heat_\" in f and \"_crop\" in f]\n",
        "    mp4s = [f for f in files if f.endswith(\".mp4\")]\n",
        "    print(f\"  {user_name}: {len(src_full)} frames, {len(heat_crop)} crops, MP4: {len(mp4s)}\")\n",
        "\n",
        "# Summary for every user that has output (after running the pipeline)\n",
        "print(\"Output summary (users with frames/ folder):\")\n",
        "for user in user_folders:\n",
        "    check_output_files(user)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
